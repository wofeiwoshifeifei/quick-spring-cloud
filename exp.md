事务中包含外部调用
 

外部调用包括对外部系统的调用和基础组件的调用。它具有返回时间不确定性的特征，必然会造成大事务。大的数据库事务会造成其它对数据库连接的请求获取不到，那么和这个数据库相关的所有服务都很可能处于等待状态，造成连接池被打满，多个服务直接宕掉。如果这个没做好，危险指数五颗星。下面的图显示出外部调用时间的不可控：

 



 

超时时间和重试次数不合理
 

对外部系统和缓存、消息队列等基础组件的依赖，如果超时时间设置过长、重试过多，系统长时间不返回，可能会导致连接池被打满，系统死掉；如果超时时间设置过短，499错误会增多，系统的可用性会降低。如果超时时间设置得短，重试次数设置得多，会增加系统的整体耗时；如果超时时间设置得短，重试次数设置得也少，那么这次请求的返回结果会不准确。波士顿矩阵分析图如下：



 

举个例子：


服务A依赖于两个服务的数据完成此次操作。平时没有问题，假如服务B在你不知道的情况下，响应时间变长，甚至停止服务，而你的客户端超时时间设置过长，则你完成此次请求的响应时间就会变长，此时如果发生意外，后果会很严重。

 

Java的Servlet容器，无论是Tomcat还是Jetty都是多线程模型，都用worker线程来处理请求。这个可配置有上限，当你的请求打满worker线程的最大值之后，剩余请求会被放到等待队列。等待队列也有上限，一旦等待队列都满了，那这台Web Server就会拒绝服务，对应到Nginx上返回就是502。如果你的服务是QPS较高的服务，那基本上这种场景下，你的服务也会跟着被拖垮。如果你的上游也没有合理的设置超时时间，那故障会继续向上扩散。这种故障逐级放大的过程，就是服务雪崩效应。

 

外部依赖的地方没有熔断
 

在依赖的服务不可用时，服务调用方应该通过一些技术手段，向上提供有损服务，保证业务柔性可用。而系统没有熔断，如果由于代码逻辑问题上线引起故障、网络问题、调用超时、业务促销调用量激增、服务容量不足等原因，服务调用链路上有一个下游服务出现故障，就可能导致接入层其它的业务不可用。下图是对无熔断影响的鱼骨图分析：



 

对于依赖我们的上游没有限流
 

在开放式的网络环境下，对外系统往往会收到很多有意无意的恶意攻击，如DDoS攻击、用户失败重刷。虽然我们的队友各个是精英，但还是要做好保障，不被上游的疏忽影响，毕竟，谁也无法保证其他同学哪天会写一个如果下游返回不符合预期就无限次重试的代码。这些内部和外部的巨量调用，如果不加以保护，往往会扩散到后台服务，最终可能引起后台基础服务宕机。下图是对无限流影响的问题树分析：



 

慢查询问题
 

慢查询会降低应用的响应性能和并发性能。在业务量增加的情况下造成数据库所在的服务器CPU利用率急剧攀升，严重的会导致数据库不响应，只能重启解决。关于慢查询，可以参考我们技术博客之前的文章《MySQL索引原理及慢查询优化》。



 

依赖不合理
 

每多一个依赖方，风险就会累加。特别是强依赖，它本身意味着一荣俱荣、一损俱损。



 

废弃逻辑和临时代码
 

过期的代码会对正常逻辑有干扰，让代码不清晰。特别是对新加入的同事，他们对明白干什么用的代码可以处理。但是已经废弃的和临时的，因为不知道干什么用的，所以改起来更忐忑。如果知道是废弃的，其它功能改了这一块没改，也有可能这块不兼容，引发问题。下图是William Pietri（曾任Code for America的研发总监）定义的代码类别，不持续维护的代码从长期成本来说是很高的：



 

没有有效的资源隔离
 

容易造成级联多米诺骨牌效应。



针对上述问题，我们提出了解决方案。

 

 
解决问题

 

1. 事务中不包含外部调用

 

排查各个系统的代码，检查在事务中是否存在RPC调用、HTTP调用、消息队列操作、缓存、循环查询等耗时的操作，这个操作应该移到事务之外，理想的情况是事务内只处理数据库操作。

对大事务添加监控报警。大事务发生时，会收到邮件和短信提醒，一般的报警标准是1s。

建议不要用XML配置事务，而采用注解的方式。原因是XML配置事务，第一可读性不强，第二切面通常配置的比较泛滥，容易造成事务过大，第三对于嵌套情况的规则不好处理。

 

 

2. 超时时间设置合理和重试次数
 

首先要调研被依赖服务自己调用下游的超时时间是多少。调用方的超时时间要大于被依赖方调用下游的时间。

统计这个接口99%的超时时间是多少，设置的超时时间在这个基础上加50%。

重试次数如果系统服务重要性高，则按照默认，一般是重试三次。否则，可以不重试。

 

3. 外部依赖的地方都要做熔断
 

自动熔断：可以使用Netflix的Hystrix或者美团点评自己研发的Rhino来做快速失败。

手动熔断：确认下游支付通道抖动或不可用，可以手动关闭通道。

 

 

4. 对于依赖我们的上游要限流
 

通过对服务端的业务性能压测，可以分析出一个相对合理的最大QPS。

可以使用Netflix的Hystrix或者美团点评自己研发的Rhino来限流。

 

5. 解决慢查询问题
 

将查询分成实时查询、近实时查询和离线查询。实时查询可穿透数据库，其它的不走数据库，可以用Elasticsearch来实现一个查询中心，处理近实时查询和离线查询。

读写分离。写走主库，读走从库。

索引优化。索引过多会影响数据库写性能。索引不够查询会慢。 

 

像核心交易这种数据库读写TPS差不多的，一般建议索引不超过4个。如果这还不能解决问题，那很可能需要调整表结构设计了。

 

对慢查询对应监控报警。我们这边设置的慢查询报警阈值是100ms。

 

6. 能去依赖就去依赖，否则尽量同步强依赖改成异步弱依赖
 

划清业务边界，只做该做的事情。

如果依赖一个系统提供的数据，上游可以作为参数传入或者下游可以作为返回值返回，则可以下线专门去取数据的逻辑，尽量让上下游给我们数据。

我们写入基础组件，数据提供给其它端，如果其它端有兜底策略，则我们可以异步写入，不用保证数据100%不丢失。

 

7. 精简代码逻辑
 

梳理每个接口的调用情况，对于没有调用量的接口，确认不再使用后及时下线。

code review保证每段逻辑都明白其含义，弄清楚是否是历史逻辑或者临时逻辑。

 

8. 核心路径进行资源隔离
 

服务器物理隔离原则

 

① 内外有别：内部系统与对外开放平台区分对待。
② 内部隔离：从上游到下游按通道从物理服务器上进行隔离，低流量服务合并。
③ 外部隔离：按渠道隔离，渠道之间互不影响。

 

线程池资源隔离

 

Hystrix通过命令模式，将每个类型的业务请求封装成对应的命令请求。每个命令请求对应一个线程池，创建好的线程池是被放入到ConcurrentHashMap中。

 

注意：尽管线程池提供了线程隔离，客户端底层代码也必须要有超时设置，不能无限制的阻塞以致于线程池一直饱和。

 

信号量资源隔离

 

开发者可以使用Hystrix限制系统对某一个依赖的最高并发数，这个基本上就是一个限流策略。每次调用依赖时都会检查一下是否到达信号量的限制值，如达到，则拒绝。

 

除了上面的措施之外，战狼项目还进行了很有成效的两地三中心机房互备、组件安全漏洞修复和服务健康验证，限于篇幅，本文就不详述了。《Clean Code》一书里说沟通是专业开发者的头等大事，我个人也认为它可以说是项目过程中最重要的环节。没有很好的沟通，就好像是越走越远的两个人，我在等着你回心转意，你却在等着自己死心，你发现心死不了，我却已经放弃了等待。永远在平行线上没有交集，只是徒增苦痛，没有意义。

 

实施后的效果

 

通过这场“飞行中换引擎”的战狼项目，线上事故急剧减少，基本上维持在零事故。监控报警从常态变成偶尔发生。为了系统性地检验效果。我们进行了多次故障演练。



演练效果符合预期，系统稳定性符合标准。这过程中有很多收获和乐趣，比如第一次演练的时候，把缓存挂掉，系统竟然跟着挂了。所以以后的每次演练都觉得这是很重要的事情。

 

就好像我3年前从一家公司离职，当时因为是冬天好多人感冒了，咳嗽。我就开玩笑跟我搭档说：“去了新公司听不到咳嗽声了会不会不适应。”搭档跟我说：“到了新公司肯定还会出现专门咳嗽给你听的人。”所以从此，我在办公室里听到咳嗽声，都会朝自己笑一笑。一件不经意的小事，让本来很多不是好事的事情变得有意义。“战狼”项目，开始是由于故障和报警引起的，肯定算不上是好事。但是这也催生出了“战狼”这样意义重大，影响深远的项目。

 

近期我们的可用性除了因为一次下游通道抖动引起的可用性6个9之外，其它时间可用性均为100%。下面为可用性趋势图。



持续跟进

 

我们优化了业务大盘、故障大盘。加强了监控报警机制，持续监控和保障着系统的稳定性。故障演练也作为了定时的日常工作来做。稳定性需要建立长期规范，维护组内的checklist，定期检查是否达到标准。checklist举例如下：　　



 

 
项目总结

 

我们家老大是像星星一样散发着智慧的人，他给我们总结系统稳定性的三个要素：第一是别人死我们不死，第二是不自己作死，第三是不被猪队友搞死。

 

稳定性具体的实施方法总结一下就是：能不依赖就去依赖，尽可能将强依赖转成弱依赖，实在不能降低依赖就保护依赖，做好自保，出了问题只能收敛不能扩大，对危险要能监控。

 

线上支付平台总结的稳定性“四板斧”：研发规范、自身稳定、容错下游、防御上游。

 

经过为期4周的战狼项目，多个小组紧密合作，日夜兼程，高效地完成了一个又一个攻坚任务，保证了交易系统的稳定。整个项目收获的不仅是一套稳定的系统，更重要的是通过一次次的激烈探讨，一场场集体推进会，总结出了一套通用的系统稳定提升方法，同时也锻炼出一只充满战斗力的队伍，为整个支付业务快速稳定发展奠定了基础。

 

所谓生于忧患，死于安乐。历史上，重大危机总是发生在承平日久之后。战狼项目虽然已经结束，但是战狼精神永存。我们要时时刻刻居安思危，保持稳定第一。

 

 

工具介绍

 

项目中多次提到使用Hystrix和Rhino。所以这里对它们做一个简单的介绍。

 

Hystrix

 

Hystrix实现了断路器模式来对故障进行监控，当断路器发现调用接口发生了长时间等待，就使用快速失败策略，向上返回一个错误响应，这样达到防止阻塞的目的。这里重点介绍一下Hystrix的线程池资源隔离和信号量资源隔离。

线程池资源隔离

 

优点

使用线程可以完全隔离第三方代码，请求线程可以快速放回。

当一个失败的依赖再次变成可用时，线程池将清理，并立即恢复可用，而不是一个长时间的恢复。

可以完全模拟异步调用，方便异步编程。

 

缺点

线程池的主要缺点是它增加了CPU，因为每个命令的执行涉及到排队（默认使用SynchronousQueue避免排队），调度和上下文切换。

对使用ThreadLocal等依赖线程状态的代码增加复杂性，需要手动传递和清理线程状态（Netflix公司内部认为线程隔离开销足够小，不会造成重大的成本或性能的影响）。

 

信号量资源隔离

 

开发者可以使用Hystrix限制系统对某一个依赖的最高并发数。这个基本上就是一个限流策略，每次调用依赖时都会检查一下是否到达信号量的限制值，如达到，则拒绝。

 

优点

不新起线程执行命令，减少上下文切换。

 

缺点

无法配置断路，每次都一定会去尝试获取信号量。

 

比较一下线程池资源隔离和信号量资源隔离

 

线程隔离是和主线程无关的其他线程来运行的；而信号量隔离是和主线程在同一个线程上做的操作。

信号量隔离也可以用于限制并发访问，防止阻塞扩散，与线程隔离的最大不同在于执行依赖代码的线程依然是请求线程。

线程池隔离适用于第三方应用或者接口、并发量大的隔离；信号量隔离适用于内部应用或者中间件；并发需求不是很大的场景。



 

Rhino

 

Rhino是美团点评基础架构团队研发并维护的一个稳定性保障组件，提供故障模拟、降级演练、服务熔断、服务限流等功能。和Hystrix对比：

 

Hystrix组件在熔断之后，并在试探线程成功之后，就直接关闭熔断开关，全部流量走正常逻辑。而Rhino会对流量进行恢复灰度。

内部通过CAT（美团点评开源的监控系统，参见之前的博客“深度剖析开源分布式监控CAT”）进行了一系列埋点，方便进行服务异常报警。

接入配置中心，能提供动态参数修改，比如强制熔断、修改失败率等